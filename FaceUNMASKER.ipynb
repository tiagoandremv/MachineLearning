{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceUNMASKER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17cwN4JDpiSqk8wPVmFt09UdOE_6m9L9n",
      "authorship_tag": "ABX9TyNZCEwdtKbp6ngaxftk1vdX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiagoandremv/MachineLearning/blob/main/FaceUNMASKER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UTB4P_jkhtC"
      },
      "source": [
        "#Importação de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC2QoQUPkjaC"
      },
      "source": [
        "# IMPORTAÇÃO DE BIBLIOTECAS NECESSÁRIAS\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy  as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, mean_squared_error, roc_auc_score, f1_score, matthews_corrcoef\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.layers    import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models    import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.losses    import SparseCategoricalCrossentropy, CategoricalCrossentropy, binary_crossentropy\n",
        "\n",
        "from random import shuffle\n",
        "from tqdm   import tqdm # permite verificar o progresso do carregamento\n",
        "\n",
        "\n",
        "class PrepareData:\n",
        "\n",
        "  def __init__(self):\n",
        "    path = '/content/drive/My Drive/Colab Notebooks/tdx_project/dataset-proj/'\n",
        "    self.train_path = path + 'train/'  \n",
        "    self.validation_path = path + 'validation/' \n",
        "\n",
        "  def label_img(self, _path):\n",
        "    word_label = _path.split('/')[-2]\n",
        "    return [1,0] if word_label == 'fake' else [0,1]\n",
        "\n",
        "  def scale_image(self, img, scale_percent = 0.5):\n",
        "    width = int(img.shape[1] * scale_percent)\n",
        "    height = int(img.shape[0] * scale_percent)\n",
        "    scale = (width, height)\n",
        "    img = cv2.resize(img, scale)\n",
        "    return img\n",
        "\n",
        "  def load_prepare_data (self, _type):\n",
        "    dataset = []\n",
        "    _path = self.train_path if _type == 'train' else self.validation_path \n",
        "    \n",
        "    for folder in os.listdir(_path): #['fake', 'real']\n",
        "      path_folder = os.path.join(_path, folder)\n",
        "      \n",
        "      for filename in tqdm(os.listdir(path_folder)):\n",
        "        path = os.path.join(path_folder, filename)\n",
        "        label = self.label_img(path) # [0,1] para real , [1,0] para fake\n",
        "\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = self.scale_image(img)\n",
        "        img = img.astype(\"float64\") / 255.0\n",
        "        #original_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   \n",
        "        \n",
        "        dataset.append([np.array(img), np.array(label)])\n",
        "    \n",
        "    shuffle(dataset)\n",
        "    return dataset    \n",
        "\n",
        "def model_train_and_evaluate(model, trainX, trainY, validationX, validationY, key=\"\"):\n",
        "  model = model.fit(trainX, trainY)\n",
        "  yproba = model.predict_proba(validationX)[::,1]\n",
        "  ypredicted = model.predict(validationX)\n",
        "  \n",
        "  fpr, tpr, _ = roc_curve(validationY,  yproba)\n",
        "  auc         = roc_auc_score(validationY, yproba)\n",
        "  conf_m      = confusion_matrix(validationY, ypredicted)\n",
        "  mcc         = matthews_corrcoef(validationY, ypredicted)\n",
        "  f1          = f1_score(validationY, ypredicted)\n",
        "  result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc','f1', 'mcc', 'confusion_matrix'])\n",
        "  result_table = result_table.append({'classifiers':model.__class__.__name__+\"-\"+key,\n",
        "                                      'fpr':fpr, \n",
        "                                      'tpr':tpr, \n",
        "                                      'auc':auc,\n",
        "                                      'confusion_matrix': conf_m,\n",
        "                                      'mcc':mcc,\n",
        "                                      'f1': f1}, ignore_index=True)\n",
        "  return result_table\n",
        "\n",
        "\n",
        "def visualize_fit_summary(hist, n_epochs):\n",
        "  acc = hist.hist['accuracy']\n",
        "  val_acc = hist.hist['val_accuracy']\n",
        "\n",
        "  loss = hist.hist['loss']\n",
        "  val_loss = hist.hist['val_loss']\n",
        "\n",
        "  epochs_range = range(n_epochs)\n",
        "\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs_range, loss, label='Training Loss')\n",
        "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.show()\n",
        "\n",
        "def plot_all_images(images):\n",
        "  for i in range(len(images)):\n",
        "    plt.subplot(1,len(images),i+1) \n",
        "    plt.imshow(images[i])\n",
        "    plt.title(titles[i])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "  plt.show()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNDk9L0qHU75"
      },
      "source": [
        "#Carregamento de Imagens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMp7KwCgQPlk",
        "outputId": "1ca83e90-5134-4188-9df8-45c569d8595d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pData = PrepareData()\n",
        "train_data = pData.load_prepare_data(_type = 'train')\n",
        "print(\"train_data Shape: \", np.asarray(train_data).shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 700/700 [00:06<00:00, 103.60it/s]\n",
            "100%|██████████| 700/700 [00:43<00:00, 16.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_data Shape:  (1400, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKJBtlagSkd4",
        "outputId": "a3b3977c-9f51-4c4e-e2c3-e8ff15640bd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "validation_data = pData.load_prepare_data(_type = 'validation')\n",
        "print(\"validation_data Shape: \", np.asarray(validation_data).shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [00:02<00:00, 106.32it/s]\n",
            "100%|██████████| 300/300 [00:18<00:00, 16.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "validation_data Shape:  (600, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY8_Pm1I2j3i"
      },
      "source": [
        "#Definição de features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohyeO5g3A4V9",
        "outputId": "6fbbabc5-3f20-4898-a0c4-faefa1ad07d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# X-Features & Y-Labels\n",
        "train_images = np.array([i[0] for i in train_data]).reshape(-1, 512, 512, 1)\n",
        "train_labels = np.array([i[1] for i in train_data]).astype('float64')\n",
        "\n",
        "validation_images = np.array([i[0] for i in validation_data]).reshape(-1, 512, 512, 1)\n",
        "validation_labels = np.array([i[1] for i in validation_data]).astype('float64')\n",
        "\n",
        "print(\"Train Images, shape and type: \", train_images.shape, train_images.dtype)\n",
        "print(\"Train Labels, shape and type: \", train_labels.shape, train_labels.dtype)\n",
        "\n",
        "print(\"Validation Images, shape and type: \", validation_images.shape, validation_images.dtype)\n",
        "print(\"Validation Labels, shape and type: \", validation_labels.shape, validation_labels.dtype)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Images, shape and type:  (1400, 512, 512, 1) float64\n",
            "Train Labels, shape and type:  (1400, 2) float64\n",
            "Validation Images, shape and type:  (600, 512, 512, 1) float64\n",
            "Validation Labels, shape and type:  (600, 2) float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PH_NcyoKcVj",
        "outputId": "4c933d73-7e95-4f18-e814-2e4b5d9df995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_images[1].max()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9137254901960784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwrfzfWRRA3a"
      },
      "source": [
        "# Definição do MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tquu_lTZvXpo",
        "outputId": "f11d9529-62c2-4a8c-e5ea-9572f63d1147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "early_callback = EarlyStopping(monitor = 'loss', patience = 2)\n",
        "inputs_shape = validation_images[0].shape\n",
        "print(\"Inputs Shape: \", inputs_shape)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, 2, activation='relu', padding='same', input_shape=inputs_shape))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, 2, activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, 2, activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(2))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss=CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs Shape:  (512, 512, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN4Pn9UPyRii",
        "outputId": "098d96f4-a7c2-4a68-80f2-ced8983b0725",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(train_images, \n",
        "                    train_labels, \n",
        "                    epochs = 30, \n",
        "                    validation_data = (validation_images, validation_labels), \n",
        "                    callbacks = [early_callback] \n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEoFiGG89euM"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mecS8xWMIZJA"
      },
      "source": [
        "visualize_fit_summary(history, 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcV3ojQalhht"
      },
      "source": [
        "# APRESENTAÇÃO DE RESULTADOS\n",
        "\n",
        "#print(\"Confusion Matrix\\n\", confusion_matrix(y_train, train_predictions))\n",
        "#print(\"Accuracy: %.2f %%\" % (accuracy_score(y_train, train_predictions) * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwc12WRfNxdf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}